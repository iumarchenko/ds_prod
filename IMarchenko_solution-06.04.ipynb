{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install imblearn\n",
    "# !pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from scipy import interp\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif, RFECV\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, precision_recall_curve, roc_curve, auc, \\\n",
    "                            log_loss, roc_auc_score, average_precision_score, confusion_matrix\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import xgboost as xgb, lightgbm as lgbm, catboost as catb\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_format(sec):\n",
    "    return str(timedelta(seconds=sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Следует из исходных данных\n",
    "CHURNED_START_DATE = '2019-09-01' \n",
    "CHURNED_END_DATE = '2019-10-01'\n",
    "\n",
    "INTER_1 = (1,7)\n",
    "INTER_2 = (8,14)\n",
    "INTER_3 = (15,21)\n",
    "INTER_4 = (22,28)\n",
    "INTER_LIST = [INTER_1, INTER_2, INTER_3, INTER_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(y_true, y_pred, y_prob):\n",
    "    precision = precision_score(y_true=y_true, y_pred=y_pred)\n",
    "    recall = recall_score(y_true=y_true, y_pred=y_pred)\n",
    "    f1 = f1_score(y_true=y_true, y_pred=y_pred)\n",
    "    ll = log_loss(y_true=y_true, y_pred=y_prob)\n",
    "    roc_auc = roc_auc_score(y_true=y_true, y_score=y_prob)\n",
    "    print('Precision: {}'.format(precision))\n",
    "    print('Recall: {}'.format(recall))\n",
    "    print('F1: {}'.format(f1))\n",
    "    print('Log Loss: {}'.format(ll)) \n",
    "    print('ROC AUC: {}'.format(roc_auc)) \n",
    "    return precision, recall, f1, ll, roc_auc\n",
    "\n",
    "def xgb_fit_predict(X_train, y_train, X_test, y_test):\n",
    "    clf = xgb.XGBClassifier(max_depth=3,\n",
    "                            n_estimators=100,\n",
    "                            learning_rate=0.1,\n",
    "                            nthread=5,\n",
    "                            subsample=1.,\n",
    "                            colsample_bytree=0.5,\n",
    "                            min_child_weight = 3,\n",
    "                            reg_alpha=0.,\n",
    "                            reg_lambda=0.,\n",
    "                            seed=42,\n",
    "                            missing=1e10)\n",
    "\n",
    "    clf.fit(X_train, y_train, eval_metric='aucpr', verbose=10)\n",
    "    predict_proba_test = clf.predict_proba(X_test)\n",
    "    predict_test = clf.predict(X_test)\n",
    "    precision_test, recall_test, f1_test, log_loss_test, roc_auc_test = \\\n",
    "        evaluation(y_test, predict_test, predict_proba_test[:, 1])\n",
    "    return clf\n",
    "\n",
    "def plot_importance(importance, features):\n",
    "    fi = pd.DataFrame(list(zip(features, importance))).sort_values(by=1, ascending=False)\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.bar(range(fi.shape[0]), fi[1], align='center')\n",
    "    plt.xticks(range(fi.shape[0]), fi[0], rotation=90)\n",
    "    plt.title('name')\n",
    "    plt.show()\n",
    "    return fi\n",
    "\n",
    "# lightgbm\n",
    "def lightgbm_fit_predict(X_train, y_train, X_test, y_test):\n",
    "    clf = lgbm.LGBMClassifier(random_state=21)\n",
    "    clf.fit(X_train, y_train) # eval_metric='aucpr', verbose=10\n",
    "    predict_proba_test = clf.predict_proba(X_test)\n",
    "    predict_test = clf.predict(X_test)\n",
    "    precision_test, recall_test, f1_test, log_loss_test, roc_auc_test = \\\n",
    "        evaluation(y_test, predict_test, predict_proba_test[:, 1])\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group(df, columns):\n",
    "    for i in columns:\n",
    "        df[i]=df[i+'_1']+df[i+'_2']+df[i+'_3']+df[i+'_4']\n",
    "        \n",
    "        df[i+'_1_gr']=0\n",
    "        df.loc[(df[i+'_1']>0), i+'_1_gr'] = 1\n",
    "        \n",
    "        df[i+'_2_gr']=0\n",
    "        df.loc[(df[i+'_2']>0), i+'_2_gr'] = 1\n",
    "        \n",
    "        df[i+'_3_gr']=0\n",
    "        df.loc[(df[i+'_3']>0), i+'_3_gr'] = 1\n",
    "        \n",
    "        df[i+'_4_gr']=0\n",
    "        df.loc[(df[i+'_4']>0), i+'_4_gr'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def around(df, columns):\n",
    "    for i in columns:\n",
    "        df[i[0]+'_1']=np.round(df[i[0]+'_1'],i[1])\n",
    "        df[i[0]+'_2']=np.round(df[i[0]+'_2'],i[1])\n",
    "        df[i[0]+'_3']=np.round(df[i[0]+'_3'],i[1])\n",
    "        df[i[0]+'_4']=np.round(df[i[0]+'_4'],i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_3std(df, columns):\n",
    "    t = []\n",
    "    for i in columns:\n",
    "        for j in range(1,5):\n",
    "            mean = np.round(df[i+'_'+str(j)].mean())\n",
    "            std3 = 3 * np.round(df[i+'_'+str(j)].std())\n",
    "            conf_interval = mean + std3\n",
    "            t.append(mean + std3)\n",
    "    return t\n",
    "\n",
    "def cutter(df, columns):\n",
    "    for i in columns:\n",
    "        m = get_3std(df, [i[0]])\n",
    "        \n",
    "        df.loc[(df[i[0]+'_1'] > m[0]), i[0]+'_1'] = df[i[0]+'_1'].mean()\n",
    "        df.loc[(df[i[0]+'_2'] > m[1]), i[0]+'_2'] = df[i[0]+'_2'].mean()\n",
    "        df.loc[(df[i[0]+'_3'] > m[2]), i[0]+'_3'] = df[i[0]+'_3'].mean()\n",
    "        df.loc[(df[i[0]+'_4'] > m[3]), i[0]+'_4'] = df[i[0]+'_4'].mean()\n",
    "        \n",
    "def has_game(df, columns):\n",
    "    for i in columns:\n",
    "        for j in range(1,5):\n",
    "            df[i+'_'+str(j)+'_b'] = 0\n",
    "            df.loc[(df[i+'_'+str(j)] > 0), i+'_'+str(j)+'_b'] = 1\n",
    "        df[i+'_b'] = 0\n",
    "        df.loc[(df[i+'_1']>0)|(df[i+'_2']>0)|(df[i+'_3']>0)|(df[i+'_4']>0), i+'_b'] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset, \n",
    "                    dataset_type='train',\n",
    "                    dataset_path='dataset/'):\n",
    "    print(dataset_type)\n",
    "    start_t = time.time()\n",
    "    print('Dealing with missing values, outliers, categorical features...')\n",
    "    \n",
    "    # Профили\n",
    "    dataset['age'] = dataset['age'].fillna(dataset['age'].mean()) #mean?\n",
    "    dataset.loc[(dataset['age'] > 70) | (dataset['age'] < 7), 'age'] = round(dataset['age'].mean())\n",
    "    \n",
    "    dataset['gender'] = dataset['gender'].fillna(dataset['gender'].mode()[0])\n",
    "    dataset.loc[~dataset['gender'].isin(['M', 'F']), 'gender'] = dataset['gender'].mode()[0]\n",
    "    dataset['gender'] = dataset['gender'].map({'M': 1, 'F':0})\n",
    "    dataset['gender'] = dataset['gender'].astype(int)\n",
    "    \n",
    "    dataset['donate_total'] = np.around(dataset['donate_total'],decimals=2) #еще раз обрезать?\n",
    "        \n",
    "    dataset['donate_total_gr'] = 0\n",
    "    dataset.loc[(dataset['donate_total']>0), 'donate_total_gr'] = 1\n",
    "    \n",
    "    dataset.loc[(dataset['level']>=10)&(dataset['level']<20) , 'level_gr'] = 1\n",
    "    dataset.loc[(dataset['level']>=20)&(dataset['level']<30) , 'level_gr'] = 2\n",
    "    dataset.loc[(dataset['level']>=30)&(dataset['level']<40) , 'level_gr'] = 3\n",
    "    dataset.loc[(dataset['level']>=40)&(dataset['level']<=50) , 'level_gr'] = 4\n",
    "    dataset['level_gr'] = dataset['level_gr'].astype(int)\n",
    "    \n",
    "    dataset.loc[(dataset['days_between_fl_df'] > 300) | (dataset['days_between_fl_df'] < -1), 'days_between_fl_df'] = \\\n",
    "                                                                round(dataset['days_between_fl_df'].mean())\n",
    "\n",
    "    dataset.loc[(dataset['days_between_reg_fl'] > 300), 'days_between_reg_fl'] = \\\n",
    "                                                                round(dataset['days_between_reg_fl'].mean())\n",
    "\n",
    "# обрезка портит\n",
    "#     cutter(dataset, [['session_player',10000]])\n",
    "\n",
    "# портит ,['silver_spent',3] ,['session_amt',0],['trans_amt',0]   \n",
    "\n",
    "    around(dataset,[['sess_with_abusers_amt',0], ['session_player',2],['reports_amt',0],['disconnect_amt',0],\n",
    "                    ['avg_min_ping',0],['kd',0],['leavings_rate',0],['win_rate',0],['gold_spent',0],\n",
    "                    ['pay_amt',0]])\n",
    "\n",
    "# портит     'session_amt''pay_amt''trans_amt' 'silver_spent'\n",
    "    group(dataset,['sess_with_abusers_amt', 'session_player','reports_amt','disconnect_amt','avg_min_ping','kd',\n",
    "                  'leavings_rate','win_rate','gold_spent'])\n",
    "       \n",
    "    # Пинги\n",
    "    for period in range(1,len(INTER_LIST)+1):\n",
    "        col = 'avg_min_ping_{}'.format(period)\n",
    "        dataset.loc[(dataset[col] < 0) | \n",
    "                    (dataset[col].isnull()), col] = dataset.loc[dataset[col] >= 0][col].mean()\n",
    "    # Сессии и прочее\n",
    "    dataset.fillna(0, inplace=True)\n",
    "    \n",
    "#  портит   \n",
    "#     has_game(dataset, ['session_player'])\n",
    "    \n",
    "    dataset.to_csv('{}dataset_{}.csv'.format(dataset_path, dataset_type, dataset_type), sep=';', index=False)\n",
    "         \n",
    "    print('Dataset is successfully prepared and saved to {}, run time (dealing with bad values): {}'.\\\n",
    "          format(dataset_path, time_format(time.time()-start_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('dataset/dataset_raw_train.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\n",
      "Dealing with missing values, outliers, categorical features...\n",
      "d:\\GB course\\cl-ser\\train\\dataset\\dataset_train.csv\n",
      "Dataset is successfully prepared and saved to d:\\GB course\\cl-ser\\, run time (dealing with bad values): 0:00:56.791834\n"
     ]
    }
   ],
   "source": [
    "prepare_dataset(dataset=train, dataset_type='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "До: Counter({0: 318955, 1: 9677})\n",
      "После: Counter({0: 318955, 1: 98589})\n",
      "Wall time: 28.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset = pd.read_csv('dataset/dataset_train.csv', sep=';')\n",
    "X = dataset.drop(['user_id', 'is_churned'], axis=1)\n",
    "y = dataset['is_churned']\n",
    "\n",
    "X_mm = StandardScaler().fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_mm, \n",
    "                                                    y, \n",
    "                                                    test_size=0.3,\n",
    "                                                    shuffle=True, \n",
    "                                                    stratify=y, \n",
    "                                                    random_state=100)\n",
    "\n",
    "# Снизим дизбаланс классов\n",
    "smote_on_1 = int(X_train.shape[0]*3/10) \n",
    "X_train_balanced, y_train_balanced = SMOTE(random_state=42, sampling_strategy={1: smote_on_1}). \\\n",
    "                                        fit_sample(X_train, y_train) \n",
    "\n",
    "print('До:', Counter(y_train.values))\n",
    "print('После:', Counter(y_train_balanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3310996563573883\n",
      "Recall: 0.4645612343297975\n",
      "F1: 0.38663723916532905\n",
      "Log Loss: 0.12016098764676494\n",
      "ROC AUC: 0.9145047856755335\n",
      "Wall time: 46.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "fitted_clf = xgb_fit_predict(X_train_balanced, y_train_balanced, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('dataset/dataset_raw_test.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Dealing with missing values, outliers, categorical features...\n",
      "d:\\GB course\\cl-ser\\test\\dataset\\dataset_test.csv\n",
      "Dataset is successfully prepared and saved to d:\\GB course\\cl-ser\\, run time (dealing with bad values): 0:00:05.794155\n"
     ]
    }
   ],
   "source": [
    "prepare_dataset(dataset=test, dataset_type='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 862 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dataset = pd.read_csv('dataset/dataset_test.csv', sep=';')\n",
    "X = dataset.drop(['user_id'], axis=1)\n",
    "\n",
    "X_test = StandardScaler().fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = fitted_clf.predict(X_test)\n",
    "predict_proba_test = fitted_clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.concat([dataset['user_id'], pd.Series(predict_test)], axis=1)\n",
    "result = result.rename(columns={0: 'is_churned'})\n",
    "result.to_csv('IMarchenko_predictions.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
